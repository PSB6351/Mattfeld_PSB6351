{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I will use the following notebook to demonstrate different steps in preprocessing\n",
    "\n",
    "## These steps will include:\n",
    "\n",
    "### 1) Slice timing correction\n",
    "### 2) Motion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Import new things that we'll need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nipype.interfaces.afni as afni\n",
    "import nipype.interfaces.fsl as fsl\n",
    "import nipype.interfaces.freesurfer as fs\n",
    "from nipype.interfaces.utility import Function\n",
    "import seaborn as sns\n",
    "import nibabel as nb\n",
    "import json\n",
    "import nipype.interfaces.io as nio\n",
    "import nipype.pipeline.engine as pe \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I next want to get a list of all of my functional files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = ['021']\n",
    "base_dir = '/home/ssuss007/Mattfeld_PSB6351/option_2'\n",
    "work_dir = '/scratch/classroom/psb6351/suss007'\n",
    "func_dir = os.path.join(base_dir, f'dset/sub-{sid[0]}/ses-1/func')\n",
    "fmap_dir = os.path.join(base_dir, f'dset/sub-{sid[0]}/ses-1/fmap')\n",
    "fs_dir = os.path.join(base_dir, 'derivatives', 'freesurfer')\n",
    "\n",
    "# Get a list of my study task json and nifti converted files\n",
    "func_json = sorted(glob(func_dir + '/*.json'))\n",
    "func_files = sorted(glob(func_dir + '/*.nii.gz'))\n",
    "fmap_files = sorted(glob(fmap_dir + '/*func*.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ssuss007/Mattfeld_PSB6351/option_2/dset/sub-021/ses-1/func/sub-021_loc_ROI_run-1_bold.json',\n",
       " '/home/ssuss007/Mattfeld_PSB6351/option_2/dset/sub-021/ses-1/func/sub-021_loc_ROI_run-2_bold.json',\n",
       " '/home/ssuss007/Mattfeld_PSB6351/option_2/dset/sub-021/ses-1/func/sub-021_task-study_run-1_bold.json',\n",
       " '/home/ssuss007/Mattfeld_PSB6351/option_2/dset/sub-021/ses-1/func/sub-021_task-study_run-2_bold.json',\n",
       " '/home/ssuss007/Mattfeld_PSB6351/option_2/dset/sub-021/ses-1/func/sub-021_task-study_run-3_bold.json',\n",
       " '/home/ssuss007/Mattfeld_PSB6351/option_2/dset/sub-021/ses-1/func/sub-021_task-study_run-4_bold.json']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next I want to build and run function to perform slice timing correction. I'm going to have to extract some important information from the .json files like the multiband slicetiming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221013-10:08:12,126 nipype.workflow INFO:\n",
      "\t Workflow psb6351_wf settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "221013-10:08:12,183 nipype.workflow INFO:\n",
      "\t Running in parallel.\n",
      "221013-10:08:12,189 nipype.workflow INFO:\n",
      "\t Pending[0] Submitting[3] jobs Slots[inf]\n",
      "221013-10:08:12,191 nipype.workflow INFO:\n",
      "\t Submitting: psb6351_wf.id_outliers ID: 0\n",
      "221013-10:08:12,195 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"psb6351_wf.id_outliers\".\n",
      "221013-10:08:12,408 nipype.workflow INFO:\n",
      "\t Finished submitting: psb6351_wf.id_outliers ID: 0\n",
      "221013-10:08:12,458 nipype.workflow INFO:\n",
      "\t Submitting: psb6351_wf.getsubs ID: 2\n",
      "221013-10:08:12,474 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"psb6351_wf.getsubs\".\n",
      "221013-10:08:12,702 nipype.workflow INFO:\n",
      "\t Finished submitting: psb6351_wf.getsubs ID: 2\n",
      "221013-10:08:12,707 nipype.workflow INFO:\n",
      "\t Pending[2] Submitting[6] jobs Slots[inf]\n",
      "221013-10:08:12,709 nipype.workflow INFO:\n",
      "\t Submitting: _tshifter0 ID: 7\n",
      "221013-10:08:12,730 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_tshifter0\".\n",
      "221013-10:08:12,947 nipype.workflow INFO:\n",
      "\t Finished submitting: _tshifter0 ID: 7\n",
      "221013-10:08:12,965 nipype.workflow INFO:\n",
      "\t Submitting: _tshifter1 ID: 8\n",
      "221013-10:08:12,990 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_tshifter1\".\n",
      "221013-10:08:13,214 nipype.workflow INFO:\n",
      "\t Finished submitting: _tshifter1 ID: 8\n",
      "221013-10:08:13,233 nipype.workflow INFO:\n",
      "\t Submitting: _tshifter2 ID: 9\n",
      "221013-10:08:13,259 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_tshifter2\".\n",
      "221013-10:08:13,495 nipype.workflow INFO:\n",
      "\t Finished submitting: _tshifter2 ID: 9\n",
      "221013-10:08:13,516 nipype.workflow INFO:\n",
      "\t Submitting: _tshifter3 ID: 10\n",
      "221013-10:08:13,544 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_tshifter3\".\n",
      "221013-10:08:13,994 nipype.workflow INFO:\n",
      "\t Finished submitting: _tshifter3 ID: 10\n",
      "221013-10:08:14,14 nipype.workflow INFO:\n",
      "\t Submitting: _tshifter4 ID: 11\n",
      "221013-10:08:14,41 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_tshifter4\".\n",
      "221013-10:08:14,254 nipype.workflow INFO:\n",
      "\t Finished submitting: _tshifter4 ID: 11\n",
      "221013-10:08:14,271 nipype.workflow INFO:\n",
      "\t Submitting: _tshifter5 ID: 12\n",
      "221013-10:08:14,279 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_tshifter5\".\n",
      "221013-10:08:14,503 nipype.workflow INFO:\n",
      "\t Finished submitting: _tshifter5 ID: 12\n",
      "221013-10:08:14,898 nipype.workflow INFO:\n",
      "\t [Job 2] Completed (psb6351_wf.getsubs).\n",
      "221013-10:08:28,923 nipype.workflow INFO:\n",
      "\t [Job 0] Completed (psb6351_wf.id_outliers).\n",
      "221013-10:08:30,86 nipype.workflow INFO:\n",
      "\t Pending[6] Submitting[1] jobs Slots[inf]\n",
      "221013-10:08:30,108 nipype.workflow INFO:\n",
      "\t Submitting: psb6351_wf.getbestvol ID: 3\n",
      "221013-10:08:30,145 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"psb6351_wf.getbestvol\".\n",
      "221013-10:08:30,382 nipype.workflow INFO:\n",
      "\t Finished submitting: psb6351_wf.getbestvol ID: 3\n",
      "221013-10:08:33,975 nipype.workflow INFO:\n",
      "\t [Job 3] Completed (psb6351_wf.getbestvol).\n",
      "221013-10:08:33,997 nipype.workflow INFO:\n",
      "\t Pending[6] Submitting[1] jobs Slots[inf]\n",
      "221013-10:08:34,22 nipype.workflow INFO:\n",
      "\t Submitting: psb6351_wf.extractref ID: 4\n",
      "221013-10:08:34,46 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"psb6351_wf.extractref\".\n",
      "221013-10:08:34,281 nipype.workflow INFO:\n",
      "\t Finished submitting: psb6351_wf.extractref ID: 4\n",
      "221013-10:08:42,19 nipype.workflow INFO:\n",
      "\t [Job 4] Completed (psb6351_wf.extractref).\n",
      "221013-10:09:12,871 nipype.workflow INFO:\n",
      "\t [Job 7] Completed (_tshifter0).\n",
      "221013-10:09:13,61 nipype.workflow INFO:\n",
      "\t [Job 8] Completed (_tshifter1).\n",
      "221013-10:09:21,298 nipype.workflow INFO:\n",
      "\t [Job 11] Completed (_tshifter4).\n",
      "221013-10:09:21,503 nipype.workflow INFO:\n",
      "\t [Job 12] Completed (_tshifter5).\n",
      "221013-10:09:22,920 nipype.workflow INFO:\n",
      "\t [Job 9] Completed (_tshifter2).\n",
      "221013-10:09:23,124 nipype.workflow INFO:\n",
      "\t [Job 10] Completed (_tshifter3).\n",
      "221013-10:09:23,129 nipype.workflow INFO:\n",
      "\t Pending[0] Submitting[1] jobs Slots[inf]\n",
      "221013-10:09:23,134 nipype.workflow INFO:\n",
      "\t Submitting: psb6351_wf.tshifter ID: 1\n",
      "221013-10:09:23,146 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"psb6351_wf.tshifter\".\n",
      "221013-10:09:23,349 nipype.workflow INFO:\n",
      "\t Finished submitting: psb6351_wf.tshifter ID: 1\n",
      "221013-10:09:26,922 nipype.workflow INFO:\n",
      "\t [Job 1] Completed (psb6351_wf.tshifter).\n",
      "221013-10:09:26,927 nipype.workflow INFO:\n",
      "\t Pending[0] Submitting[1] jobs Slots[inf]\n",
      "221013-10:09:26,969 nipype.workflow INFO:\n",
      "\t Pending[0] Submitting[6] jobs Slots[inf]\n",
      "221013-10:09:26,973 nipype.workflow INFO:\n",
      "\t Submitting: _volreg0 ID: 13\n",
      "221013-10:09:26,977 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_volreg0\".\n",
      "221013-10:09:27,186 nipype.workflow INFO:\n",
      "\t Finished submitting: _volreg0 ID: 13\n",
      "221013-10:09:27,190 nipype.workflow INFO:\n",
      "\t Submitting: _volreg1 ID: 14\n",
      "221013-10:09:27,195 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_volreg1\".\n",
      "221013-10:09:27,424 nipype.workflow INFO:\n",
      "\t Finished submitting: _volreg1 ID: 14\n",
      "221013-10:09:27,427 nipype.workflow INFO:\n",
      "\t Submitting: _volreg2 ID: 15\n",
      "221013-10:09:27,435 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_volreg2\".\n",
      "221013-10:09:27,629 nipype.workflow INFO:\n",
      "\t Finished submitting: _volreg2 ID: 15\n",
      "221013-10:09:27,633 nipype.workflow INFO:\n",
      "\t Submitting: _volreg3 ID: 16\n",
      "221013-10:09:27,642 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_volreg3\".\n",
      "221013-10:09:27,889 nipype.workflow INFO:\n",
      "\t Finished submitting: _volreg3 ID: 16\n",
      "221013-10:09:27,893 nipype.workflow INFO:\n",
      "\t Submitting: _volreg4 ID: 17\n",
      "221013-10:09:27,901 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_volreg4\".\n",
      "221013-10:09:28,94 nipype.workflow INFO:\n",
      "\t Finished submitting: _volreg4 ID: 17\n",
      "221013-10:09:28,98 nipype.workflow INFO:\n",
      "\t Submitting: _volreg5 ID: 18\n",
      "221013-10:09:28,106 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_volreg5\".\n",
      "221013-10:09:28,378 nipype.workflow INFO:\n",
      "\t Finished submitting: _volreg5 ID: 18\n",
      "221013-10:11:35,467 nipype.workflow INFO:\n",
      "\t [Job 14] Completed (_volreg1).\n",
      "221013-10:11:37,290 nipype.workflow INFO:\n",
      "\t [Job 13] Completed (_volreg0).\n",
      "221013-10:12:07,309 nipype.workflow INFO:\n",
      "\t [Job 15] Completed (_volreg2).\n",
      "221013-10:12:07,506 nipype.workflow INFO:\n",
      "\t [Job 16] Completed (_volreg3).\n",
      "221013-10:12:15,512 nipype.workflow INFO:\n",
      "\t [Job 18] Completed (_volreg5).\n",
      "221013-10:12:25,606 nipype.workflow INFO:\n",
      "\t [Job 17] Completed (_volreg4).\n",
      "221013-10:12:25,612 nipype.workflow INFO:\n",
      "\t Pending[0] Submitting[1] jobs Slots[inf]\n",
      "221013-10:12:25,622 nipype.workflow INFO:\n",
      "\t Submitting: psb6351_wf.volreg ID: 5\n",
      "221013-10:12:25,654 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"psb6351_wf.volreg\".\n",
      "221013-10:12:26,61 nipype.workflow INFO:\n",
      "\t Finished submitting: psb6351_wf.volreg ID: 5\n",
      "221013-10:12:31,273 nipype.workflow INFO:\n",
      "\t [Job 5] Completed (psb6351_wf.volreg).\n",
      "221013-10:12:31,279 nipype.workflow INFO:\n",
      "\t Pending[0] Submitting[1] jobs Slots[inf]\n",
      "221013-10:12:31,281 nipype.workflow INFO:\n",
      "\t Submitting: psb6351_wf.datasink ID: 6\n",
      "221013-10:12:31,341 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"psb6351_wf.datasink\".\n",
      "221013-10:12:31,534 nipype.workflow INFO:\n",
      "\t Finished submitting: psb6351_wf.datasink ID: 6\n",
      "221013-10:18:55,736 nipype.workflow INFO:\n",
      "\t [Job 6] Completed (psb6351_wf.datasink).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7f875f80a250>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here I am building a function that eliminates the\n",
    "# mapnode directory structure and assists in saving\n",
    "# all of the outputs into a single directory\n",
    "def get_subs(func_files):\n",
    "    '''Produces Name Substitutions for Each Contrast'''\n",
    "    subs = []\n",
    "    for curr_run in range(len(func_files)):\n",
    "        subs.append(('_tshifter%d' %curr_run, ''))\n",
    "        subs.append(('_volreg%d' %curr_run, ''))\n",
    "    return subs\n",
    "\n",
    "# Here I am building a function that takes in a\n",
    "# text file that includes the number of outliers\n",
    "# at each volume and then finds which volume (e.g., index)\n",
    "# has the minimum number of outliers (e.g., min) \n",
    "# searching over the first 201 volumes\n",
    "# If the index function returns a list because there were\n",
    "# multiple volumes with the same outlier count, pick the first one\n",
    "def best_vol(outlier_count):\n",
    "    best_vol_num = outlier_count.index(min(outlier_count[:200]))\n",
    "    if isinstance(best_vol_num, list):\n",
    "        best_vol_num = best_vol_num[0]\n",
    "    return best_vol_num\n",
    "\n",
    "# Here I am creating a list of lists containing the slice timing for each study run\n",
    "slice_timing_list = []\n",
    "for curr_json in func_json:\n",
    "    curr_json_data = open(curr_json)\n",
    "    curr_func_metadata = json.load(curr_json_data)\n",
    "    slice_timing_list.append(curr_func_metadata['SliceTiming'])\n",
    "\n",
    "# Here I am establishing a nipype work flow that I will eventually execute\n",
    "psb6351_wf = pe.Workflow(name='psb6351_wf')\n",
    "psb6351_wf.base_dir = work_dir + f'/psb6351workdir/sub-{sid[0]}'\n",
    "psb6351_wf.config['execution']['use_relative_paths'] = True\n",
    "\n",
    "# Create a Function node to substitute names of files created during pipeline\n",
    "getsubs = pe.Node(Function(input_names=['func_files'],\n",
    "                           output_names=['subs'],\n",
    "                           function=get_subs),\n",
    "                  name='getsubs')\n",
    "getsubs.inputs.func_files = func_files\n",
    "\n",
    "# Here I am inputing just the first run functional data\n",
    "# I want to use afni's 3dToutcount to find the number of \n",
    "# outliers at each volume.  I will use this information to\n",
    "# later select the earliest volume with the least number of outliers\n",
    "# to serve as the base for the motion correction\n",
    "id_outliers = pe.Node(afni.OutlierCount(),\n",
    "                      name = 'id_outliers')\n",
    "id_outliers.inputs.in_file = func_files[0]\n",
    "id_outliers.inputs.automask = True\n",
    "id_outliers.inputs.out_file = 'outlier_file'\n",
    "\n",
    "# Create a Function node to identify the best volume based\n",
    "# on the number of outliers at each volume. I'm searching\n",
    "# for the index in the first 201 volumes that has the \n",
    "# minimum number of outliers and will use the min() function\n",
    "# I will use the index function to get the best vol. \n",
    "getbestvol = pe.Node(Function(input_names=['outlier_count'],\n",
    "                              output_names=['best_vol_num'],\n",
    "                              function=best_vol),\n",
    "                     name='getbestvol')\n",
    "psb6351_wf.connect(id_outliers, 'out_file', getbestvol, 'outlier_count')\n",
    "\n",
    "# Extract the earliest volume with the\n",
    "# the fewest outliers of the first run as the reference \n",
    "extractref = pe.Node(fsl.ExtractROI(t_size=1),\n",
    "                     name = \"extractref\")\n",
    "extractref.inputs.in_file = func_files[0]\n",
    "#extractref.inputs.t_min = int(np.ceil(nb.load(study_func_files[0]).shape[3]/2)) #PICKING MIDDLE\n",
    "psb6351_wf.connect(getbestvol, 'best_vol_num', extractref, 't_min')\n",
    "\n",
    "# Below is the command that runs AFNI's 3dTshift command\n",
    "# this is the node that performs the slice timing correction\n",
    "# I input the study func files as a list and the slice timing \n",
    "# as a list of lists. I'm using a MapNode to iterate over the two.\n",
    "# this should allow me to parallelize this on the HPC\n",
    "tshifter = pe.MapNode(afni.TShift(),\n",
    "                      iterfield=['in_file','slice_timing'],\n",
    "                      name = 'tshifter')\n",
    "tshifter.inputs.tr = '1.76'\n",
    "tshifter.inputs.slice_timing = slice_timing_list\n",
    "tshifter.inputs.outputtype = 'NIFTI_GZ'\n",
    "tshifter.inputs.in_file = func_files\n",
    "\n",
    "# Below is the command that runs AFNI's 3dvolreg command.\n",
    "# this is the node that performs the motion correction\n",
    "# I'm iterating over the functional files which I am passing\n",
    "# functional data from the slice timing correction node before\n",
    "# I'm using the earliest volume with the least number of outliers\n",
    "# during the first run as the base file to register to.\n",
    "volreg = pe.MapNode(afni.Volreg(),\n",
    "                    iterfield=['in_file'],\n",
    "                    name = 'volreg')\n",
    "volreg.inputs.outputtype = 'NIFTI_GZ'\n",
    "psb6351_wf.connect(tshifter, 'out_file', volreg, 'in_file')\n",
    "psb6351_wf.connect(extractref, 'roi_file', volreg, 'basefile')\n",
    "\n",
    "# Below is the node that collects all the data and saves\n",
    "# the outputs that I am interested in. Here in this node\n",
    "# I use the substitutions input combined with the earlier\n",
    "# function to get rid of nesting\n",
    "datasink = pe.Node(nio.DataSink(), name=\"datasink\")\n",
    "datasink.inputs.base_directory = os.path.join(base_dir, 'derivatives/preproc')\n",
    "datasink.inputs.container = f'sub-{sid[0]}'\n",
    "psb6351_wf.connect(tshifter, 'out_file', datasink, 'sltime_corr')\n",
    "psb6351_wf.connect(extractref, 'roi_file', datasink, 'study_ref')\n",
    "psb6351_wf.connect(volreg, 'out_file', datasink, 'motion.@corrfile')\n",
    "psb6351_wf.connect(volreg, 'oned_matrix_save', datasink, 'motion.@matrix')\n",
    "psb6351_wf.connect(volreg, 'oned_file', datasink, 'motion.@par')\n",
    "psb6351_wf.connect(getsubs, 'subs', datasink, 'substitutions')\n",
    "\n",
    "# The following two lines set a work directory outside of my \n",
    "# local git repo and runs the workflow\n",
    "psb6351_wf.run(plugin='SLURM',\n",
    "               plugin_args={'sbatch_args': ('--partition classroom --qos pq_psb6351 --account acc_psb6351'),\n",
    "                            'overwrite':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I will load and plot the motion filesstudy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_dir = os.path.join(base_dir, f'derivatives/preproc/sub-{sid[0]}/motion')\n",
    "study_motion_files = sorted(glob(motion_dir + '/*study*_bold.1D'))\n",
    "\n",
    "for curr_mot_file in study_motion_files:\n",
    "    motion_df = pd.read_csv(curr_mot_file, sep=\"  \", header=None)\n",
    "    motion_df.columns = ['roll', 'pitch', 'yaw', 'dS', 'dL', 'dP']\n",
    "\n",
    "    num_vols = range(1, len(motion_df)+1)\n",
    "    fig, axs = plt.subplots(motion_df.shape[1], 1, figsize = (15, 10))\n",
    "    # make a little extra space between the subplots \n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "    for idx, curr_col in enumerate(motion_df.keys()):\n",
    "        axs[idx].plot(num_vols, motion_df[f'{curr_col}'])\n",
    "        axs[idx].set_xlabel('TRs')\n",
    "        axs[idx].set_ylabel(f'{curr_col}')\n",
    "        axs[idx].grid(True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135.0\n",
      "135.0\n"
     ]
    }
   ],
   "source": [
    "#changed \"study_func_file\" to \"func_file\"\n",
    "\n",
    "study_motcorr_files = sorted(glob(motion_dir + '/*.nii.gz'))\n",
    "study_motcorr_img_data = nb.load(study_motcorr_files[0]).get_fdata()\n",
    "study_orig_img_data = nb.load(func_files[0]).get_fdata()\n",
    "\n",
    "#test_motcorr_img_data.shape\n",
    "\n",
    "print(study_motcorr_img_data[50,50,32,50])\n",
    "print(study_orig_img_data[50,50,32,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#co-registration script\n",
    "\n",
    "from nipype.interfaces import fsl\n",
    "from nipype.testing import example_data\n",
    "flt = fsl.FLIRT(bins=640, cost_func='mutualinfo')\n",
    "flt.inputs.in_file = 'structural.nii'\n",
    "flt.inputs.reference = 'mni.nii'\n",
    "flt.inputs.output_type = \"NIFTI_GZ\"\n",
    "flt.cmdline \n",
    "'flirt -in structural.nii -ref mni.nii -out structural_flirt.nii.gz -omat structural_flirt.mat -bins 640 -searchcost mutualinfo'\n",
    "res = flt.run() \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
